{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extraction et similarité entre CV et Offre d'emploie"
      ],
      "metadata": {
        "id": "69Yac5TjuUwk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "XkaA9mW3SxPw"
      },
      "outputs": [],
      "source": [
        "CV={'sexe': ['Femme '], 'formation': ['Master M2 (International of Computer Science)','Deux années de classes préparatoires intégrées et deux années cycle ingénieur en Intelligence Artificielle et Génie Informatique.','Une année de spécialisation en Mathématiques-Informatique et en Physique.','Baccalauréat option physique et chimie.'], 'localisation': ['Clermont-Ferrand'], 'competences': ['Python', 'R', 'Matlab', 'ML', 'DL', 'PCA', 'NLP', 'LLMs', 'langchain', 'Django', 'Flask', 'Streamlit', 'Flutter', 'React JS', 'Mysql', 'SQLite', 'Oracle', 'Mongodb', 'Git', 'Power BI', 'Jupyter', 'Google Colab', 'Tensorboard', 'MLflow '], 'experiences': [\"2 ans\"]}\n",
        "# CV={'sexe': ['Femme '], 'formation': ['BSc (Hons) Business Information Technology & Human Resource Management', 'Nuneaton University 2005 - 2008', 'A levels: Maths (A) English (B) Technology (B) Science (C) Coventry Central College 2003 - 2005', 'ITEC level 2 Certificate in Human Resources'], 'localisation': ['Coventry'], 'competences': ['Recrutement', 'relations avec les employés', 'administration de la paie', 'gestion de la performance', \"législation sur l\\\\'emploi\", 'rédaction de rapports financiers', 'égalité des chances', 'gestion des absences', 'administration', 'communication', 'planification', 'prise de décision'], 'experiences': ['15 années']}\n",
        "Offre={\n",
        "  \"sexe\": [\n",
        "  ],\n",
        "  \"formation\": [\n",
        "    \"Diplôme d\\\\'ingénieur\",\n",
        "    \"Master 2 \"\n",
        "  ],\n",
        "  \"localisation\": [\n",
        "    \"Paris 15e Arrondissement\"\n",
        "  ],\n",
        "  \"competences\": [\n",
        "    \"Python\",\n",
        "    \"pandas\",\n",
        "    \"numpy\",\n",
        "    \"scikit-learn\",\n",
        "    \"Machine Learning\",\n",
        "    \"Deep Learning\",\n",
        "    \"NLP\",\n",
        "    \"concepts statistiques\",\n",
        "    \"PowerShell\",\n",
        "    \"Bash\",\n",
        "    \"Git\",\n",
        "    \"DevSecOps\",\n",
        "    \"orchestration de conteneurs\",\n",
        "    \"systèmes d\\\\'exploitation (Windows\",\n",
        "    \"Linux)\"\n",
        "  ],\n",
        "  \"experiences\": [\n",
        "    \"3 ans\"\n",
        "  ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yiw09AhvUS2",
        "outputId": "e13975e0-896b-4851-9eae-2bb849d0661c"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sexe': ['Femme '],\n",
              " 'formation': ['Master M2 (International of Computer Science)',\n",
              "  'Deux années de classes préparatoires intégrées et deux années cycle ingénieur en Intelligence Artificielle et Génie Informatique.',\n",
              "  'Une année de spécialisation en Mathématiques-Informatique et en Physique.',\n",
              "  'Baccalauréat option physique et chimie.'],\n",
              " 'localisation': ['Clermont-Ferrand'],\n",
              " 'competences': ['Python',\n",
              "  'R',\n",
              "  'Matlab',\n",
              "  'ML',\n",
              "  'DL',\n",
              "  'PCA',\n",
              "  'NLP',\n",
              "  'LLMs',\n",
              "  'langchain',\n",
              "  'Django',\n",
              "  'Flask',\n",
              "  'Streamlit',\n",
              "  'Flutter',\n",
              "  'React JS',\n",
              "  'Mysql',\n",
              "  'SQLite',\n",
              "  'Oracle',\n",
              "  'Mongodb',\n",
              "  'Git',\n",
              "  'Power BI',\n",
              "  'Jupyter',\n",
              "  'Google Colab',\n",
              "  'Tensorboard',\n",
              "  'MLflow '],\n",
              " 'experiences': ['2 ans']}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Offre"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHG_usdMvcM_",
        "outputId": "ecf5e611-99bc-48eb-bcd2-68fc543f4ed7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sexe': [],\n",
              " 'formation': [\"Diplôme d\\\\'ingénieur\", 'Master 2 '],\n",
              " 'localisation': ['Paris 15e Arrondissement'],\n",
              " 'competences': ['Python',\n",
              "  'pandas',\n",
              "  'numpy',\n",
              "  'scikit-learn',\n",
              "  'Machine Learning',\n",
              "  'Deep Learning',\n",
              "  'NLP',\n",
              "  'concepts statistiques',\n",
              "  'PowerShell',\n",
              "  'Bash',\n",
              "  'Git',\n",
              "  'DevSecOps',\n",
              "  'orchestration de conteneurs',\n",
              "  \"systèmes d\\\\'exploitation (Windows\",\n",
              "  'Linux)'],\n",
              " 'experiences': ['3 ans']}"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Problème: Ajout d'information supplémentaire (exemple Master M2 International of Computer Science et Master M2)**"
      ],
      "metadata": {
        "id": "Wss7qwoR_LYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "import spacy\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Load the French language model in spaCy\n",
        "# !python -m spacy download fr_core_news_sm\n",
        "\n",
        "# nlp = spacy.load('fr_core_news_sm')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "abbreviation_dict = {\n",
        "    'ml': 'machine learning',\n",
        "    'f':\"femme\",\n",
        "    'h': \"homme\",\n",
        "    'dl': 'deep learning',\n",
        "    'ai': 'artificial intelligence',\n",
        "    'rh':\"ressources humaines\",\n",
        "    'm2': \"master 2\",\n",
        "    'ing': \"ingénieur\"\n",
        "\n",
        "}\n",
        "\n",
        "degrees=[\"deug\",\"deust\",\"licence\",\"master\",\"doctorat\",\"ingénieur\"]\n",
        "\n",
        "years_suffix=[\"an\",\"année\",\"ans\",\"années\"]\n",
        "\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    words = text.split()\n",
        "    return ' '.join([lemmatizer.lemmatize(word) for word in words])\n",
        "\n",
        "def array_to_text(arr):\n",
        "    return ' '.join(arr)\n",
        "\n",
        "def expand_abbreviations(text):\n",
        "    words = text.split()\n",
        "    expanded_text = ' '.join([abbreviation_dict.get(word, word) for word in words])\n",
        "    return expanded_text\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    # text = re.sub(r'[\\\\]', '', text)\n",
        "    text = re.sub(r\"[^\\w\\s']\", '', text)\n",
        "\n",
        "    #Méthode 1:\n",
        "    text = re.sub(r\"\\b(le|la|les|de|des|du|d'|l')\\b\", ' ', text)\n",
        "\n",
        "    #Méthode 2:\n",
        "    # Parse the text using spaCy\n",
        "    # doc = nlp(text)\n",
        "\n",
        "    # Remove French articles\n",
        "    # articles = {\"le\", \"la\", \"les\", \"de\", \"des\", \"du\", \"d'\", \"l'\", \"un\", \"une\"}\n",
        "    # text = ' '.join([token.text for token in doc if token.text not in articles])\n",
        "\n",
        "    text = lemmatize_text(text)\n",
        "    text = expand_abbreviations(text)\n",
        "    return text\n",
        "\n",
        "def compute_similarity(text1, text2):\n",
        "    # Assure que les deux textes ne sont pas vides\n",
        "    if not text1.strip() or not text2.strip():\n",
        "        return 0  # ou une autre valeur par défaut si l'un des textes est vide\n",
        "\n",
        "    # Configuration de TfidfVectorizer pour inclure des chiffres\n",
        "    vectorizer = TfidfVectorizer(analyzer='word', token_pattern=r'\\b\\w+\\b')\n",
        "    vectors = vectorizer.fit_transform([text1, text2])\n",
        "    return cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
        "\n",
        "# Rendre les éléments des listes en minuscules et les lemmatiser\n",
        "for key in CV:\n",
        "    CV[key] = [preprocess_text(element) for element in CV[key]]\n",
        "for key in Offre:\n",
        "    Offre[key] = [preprocess_text(element)  for element in Offre[key]]\n",
        "\n",
        "# Conversion des dictionnaires en texte\n",
        "#sexe\n",
        "if CV['sexe']:\n",
        "  sexe_CV = CV['sexe'][0]\n",
        "if Offre['sexe']:\n",
        "  sexe_offre = Offre['sexe'][0]\n",
        "else:\n",
        "  sexe_offre=\"\"\n",
        "\n",
        "#formation\n",
        "filtered_Offre_formation=([elem for item in Offre['formation'] for elem in item.split() ])\n",
        "filtered_CV_formation = ' '.join(set([elem for item in CV['formation'] for elem in item.split() if elem in filtered_Offre_formation]))\n",
        "formation_offre = array_to_text(filtered_Offre_formation)\n",
        "\n",
        "#competences\n",
        "filtered_CV_competence = ' '.join([item for item in CV['competences'] if item in Offre['competences']])\n",
        "competences_offre = array_to_text(Offre['competences'])\n",
        "\n",
        "#experience\n",
        "filtered_Offre_experience = ' '.join([\n",
        "    str(0) if elem == 'débutant' else\n",
        "    str(2) if elem == 'junior' else\n",
        "    str(5) if elem == 'senior' else\n",
        "    elem\n",
        "    for item in Offre['experiences']\n",
        "    for elem in item.split()\n",
        "    if elem not in years_suffix\n",
        "])\n",
        "\n",
        "# filtered_CV_experience = ' '.join(set([elem for item in CV['experiences'] for elem in item.split() if elem in filtered_Offre_experience]))\n",
        "filtered_CV_experience = ' '.join(set([elem for item in CV['experiences'] for elem in item.split() if elem not in years_suffix]))\n",
        "experience_offre = array_to_text(filtered_Offre_experience)\n",
        "\n",
        "# Calcul de la cosine similarity\n",
        "if sexe_CV and sexe_offre:\n",
        "  cosine_sim_sexe = compute_similarity(sexe_CV,sexe_offre)\n",
        "cosine_sim_formation = compute_similarity(filtered_CV_formation,formation_offre)\n",
        "cosine_sim_competences = compute_similarity(filtered_CV_competence,competences_offre)\n",
        "cosine_sim_experiences = compute_similarity(filtered_CV_experience,experience_offre)\n",
        "\n",
        "if cosine_sim_experiences == 1 or (filtered_CV_experience and filtered_Offre_experience and float(filtered_CV_experience) >= float(filtered_Offre_experience)):\n",
        "  cosine_sim_experiences=1\n",
        "else:\n",
        "  cosine_sim_experiences=0\n",
        "\n",
        "if sexe_offre!='femme' and sexe_offre!='homme':\n",
        "  cosine_sim_sexe=1\n",
        "\n",
        "if cosine_sim_competences==0:\n",
        "  cosine_sim_experiences=0\n",
        "\n",
        "cosine_sim=(cosine_sim_sexe+cosine_sim_formation+cosine_sim_competences+cosine_sim_experiences)/4\n",
        "\n",
        "if cosine_sim_sexe==0:\n",
        "  cosine_sim=0\n",
        "\n",
        "print(f\"Similarité Cosine : {cosine_sim}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1FZKPrIvdT6",
        "outputId": "f70b4a2c-3de3-44a1-c10f-cda5453aa550"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarité Cosine : 0.5680073564323089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}